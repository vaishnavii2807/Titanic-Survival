{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "x = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldata = dataset\n",
    "y = finaldata.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldata.drop(finaldata.columns[[0, 3, 8, 9, 11]],axis=1,inplace=True)\n",
    "#df.drop(df.columns[[0, 4, 2]], axis = 1, inplace = True) \n",
    "finaldata.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>G6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>D33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass     Sex   Age  SibSp  Parch        Cabin\n",
       "1          1       1  female  38.0      1      0          C85\n",
       "3          1       1  female  35.0      1      0         C123\n",
       "6          0       1    male  54.0      0      0          E46\n",
       "10         1       3  female   4.0      1      1           G6\n",
       "11         1       1  female  58.0      0      0         C103\n",
       "21         1       2    male  34.0      0      0          D56\n",
       "23         1       1    male  28.0      0      0           A6\n",
       "27         0       1    male  19.0      3      2  C23 C25 C27\n",
       "52         1       1  female  49.0      1      0          D33\n",
       "54         0       1    male  65.0      0      1          B30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Sex','SibSp','Parch','Cabin']:\n",
    "\n",
    "    dummies = pd.get_dummies(finaldata[column])\n",
    "    finaldata[dummies.columns] = dummies\n",
    "    finaldata.drop(column,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding dependent variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>E68</th>\n",
       "      <th>E77</th>\n",
       "      <th>E8</th>\n",
       "      <th>F G63</th>\n",
       "      <th>F G73</th>\n",
       "      <th>F2</th>\n",
       "      <th>F33</th>\n",
       "      <th>F4</th>\n",
       "      <th>G6</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass   Age  female  male  0  1  2  3  4  ...  E68  E77  E8  \\\n",
       "1           1       1  38.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "3           1       1  35.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "6           0       1  54.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "10          1       3   4.0       1     0  0  1  0  0  0  ...    0    0   0   \n",
       "11          1       1  58.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "21          1       2  34.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "23          1       1  28.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "27          0       1  19.0       0     1  0  0  1  1  0  ...    0    0   0   \n",
       "52          1       1  49.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "54          0       1  65.0       0     1  0  1  0  0  0  ...    0    0   0   \n",
       "61          1       1  38.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "62          0       1  45.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "66          1       2  29.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "75          0       3  25.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "88          1       1  23.0       1     0  0  0  1  1  0  ...    0    0   0   \n",
       "92          0       1  46.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "96          0       1  71.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "97          1       1  23.0       0     1  0  1  0  0  0  ...    0    0   0   \n",
       "102         0       1  21.0       0     1  0  1  0  0  0  ...    0    0   0   \n",
       "110         0       1  47.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "\n",
       "     F G63  F G73  F2  F33  F4  G6  T  \n",
       "1        0      0   0    0   0   0  0  \n",
       "3        0      0   0    0   0   0  0  \n",
       "6        0      0   0    0   0   0  0  \n",
       "10       0      0   0    0   0   1  0  \n",
       "11       0      0   0    0   0   0  0  \n",
       "21       0      0   0    0   0   0  0  \n",
       "23       0      0   0    0   0   0  0  \n",
       "27       0      0   0    0   0   0  0  \n",
       "52       0      0   0    0   0   0  0  \n",
       "54       0      0   0    0   0   0  0  \n",
       "61       0      0   0    0   0   0  0  \n",
       "62       0      0   0    0   0   0  0  \n",
       "66       0      0   0    1   0   0  0  \n",
       "75       0      1   0    0   0   0  0  \n",
       "88       0      0   0    0   0   0  0  \n",
       "92       0      0   0    0   0   0  0  \n",
       "96       0      0   0    0   0   0  0  \n",
       "97       0      0   0    0   0   0  0  \n",
       "102      0      0   0    0   0   0  0  \n",
       "110      0      0   0    0   0   0  0  \n",
       "\n",
       "[20 rows x 144 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3 ... 'A/5 21171' 7.25 nan]\n",
      " [2 1 1 ... 'PC 17599' 71.2833 'C85']\n",
      " [3 1 3 ... 'STON/O2. 3101282' 7.925 nan]\n",
      " ...\n",
      " [889 0 3 ... 'W./C. 6607' 23.45 nan]\n",
      " [890 1 1 ... '111369' 30.0 'C148']\n",
      " [891 0 3 ... '370376' 7.75 nan]]\n"
     ]
    }
   ],
   "source": [
    "#missing data (numeric):\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x[:, 5:7])\n",
    "x[:, 5:7] = imputer.transform(x[:, 5:7])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3 ... 'A/5 21171' 7.25 nan]\n",
      " [2 1 1 ... 'PC 17599' 71.2833 'C85']\n",
      " [3 1 3 ... 'STON/O2. 3101282' 7.925 nan]\n",
      " ...\n",
      " [889 0 3 ... 'W./C. 6607' 23.45 nan]\n",
      " [890 1 1 ... '111369' 30.0 'C148']\n",
      " [891 0 3 ... '370376' 7.75 nan]]\n"
     ]
    }
   ],
   "source": [
    "#missing data (string):\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='constant')\n",
    "imputer.fit(x[:, 8:-1])\n",
    "x[:, 8:-1] = imputer.transform(x[:, 8:-1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>E68</th>\n",
       "      <th>E77</th>\n",
       "      <th>E8</th>\n",
       "      <th>F G63</th>\n",
       "      <th>F G73</th>\n",
       "      <th>F2</th>\n",
       "      <th>F33</th>\n",
       "      <th>F4</th>\n",
       "      <th>G6</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass   Age  female  male  0  1  2  3  4  ...  E68  E77  E8  \\\n",
       "1          1       1  38.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "3          1       1  35.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "6          0       1  54.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "10         1       3   4.0       1     0  0  1  0  0  0  ...    0    0   0   \n",
       "11         1       1  58.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "21         1       2  34.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "23         1       1  28.0       0     1  1  0  0  0  0  ...    0    0   0   \n",
       "27         0       1  19.0       0     1  0  0  1  1  0  ...    0    0   0   \n",
       "52         1       1  49.0       1     0  1  0  0  0  0  ...    0    0   0   \n",
       "54         0       1  65.0       0     1  0  1  0  0  0  ...    0    0   0   \n",
       "\n",
       "    F G63  F G73  F2  F33  F4  G6  T  \n",
       "1       0      0   0    0   0   0  0  \n",
       "3       0      0   0    0   0   0  0  \n",
       "6       0      0   0    0   0   0  0  \n",
       "10      0      0   0    0   0   1  0  \n",
       "11      0      0   0    0   0   0  0  \n",
       "21      0      0   0    0   0   0  0  \n",
       "23      0      0   0    0   0   0  0  \n",
       "27      0      0   0    0   0   0  0  \n",
       "52      0      0   0    0   0   0  0  \n",
       "54      0      0   0    0   0   0  0  \n",
       "\n",
       "[10 rows x 144 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = finaldata.iloc[:,:].values\n",
    "y = finaldata.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 42)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "np.set_printoptions(precision = 2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.values.reshape(len(y_test),1)),1))\n",
    "#y_pred.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0]\n",
      " [ 3  1  0]\n",
      " [ 0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9361702127659575"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, metric= 'minkowski', p = 2)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 1]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "#np.set_printoptions(precision = 2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  3  0]\n",
      " [ 1  3  0]\n",
      " [ 0  0  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9148936170212766"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0]\n",
      " [ 3  1  0]\n",
      " [ 0  0  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9361702127659575"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0]\n",
      " [ 3  1  0]\n",
      " [ 0  0  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9361702127659575"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0]\n",
      " [ 0  4  0]\n",
      " [ 0  0  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0]\n",
      " [ 0  4  0]\n",
      " [ 0  0  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [3 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0]\n",
      " [ 0  3  1]\n",
      " [ 0  0  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9787234042553191"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 1.1518 - accuracy: 0.2754 - val_loss: 0.8409 - val_accuracy: 0.5106\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0472 - accuracy: 0.3116 - val_loss: 0.7874 - val_accuracy: 0.5319\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9546 - accuracy: 0.3333 - val_loss: 0.7396 - val_accuracy: 0.5532\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8739 - accuracy: 0.3768 - val_loss: 0.6976 - val_accuracy: 0.6170\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8022 - accuracy: 0.4058 - val_loss: 0.6622 - val_accuracy: 0.7021\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7402 - accuracy: 0.4420 - val_loss: 0.6323 - val_accuracy: 0.7660\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5072 - val_loss: 0.6045 - val_accuracy: 0.7660\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6253 - accuracy: 0.5290 - val_loss: 0.5792 - val_accuracy: 0.8085\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5684 - accuracy: 0.5580 - val_loss: 0.5513 - val_accuracy: 0.8085\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5173 - accuracy: 0.5797 - val_loss: 0.5225 - val_accuracy: 0.8085\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4641 - accuracy: 0.6159 - val_loss: 0.4942 - val_accuracy: 0.8298\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.6739 - val_loss: 0.4660 - val_accuracy: 0.8511\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3603 - accuracy: 0.7174 - val_loss: 0.4371 - val_accuracy: 0.8511\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3116 - accuracy: 0.7246 - val_loss: 0.4086 - val_accuracy: 0.8511\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2610 - accuracy: 0.7391 - val_loss: 0.3806 - val_accuracy: 0.8511\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2099 - accuracy: 0.7391 - val_loss: 0.3519 - val_accuracy: 0.8511\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1578 - accuracy: 0.7391 - val_loss: 0.3225 - val_accuracy: 0.8511\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1014 - accuracy: 0.7391 - val_loss: 0.2923 - val_accuracy: 0.8511\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0491 - accuracy: 0.7536 - val_loss: 0.2577 - val_accuracy: 0.8723\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.0123 - accuracy: 0.7826 - val_loss: 0.2220 - val_accuracy: 0.8723\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.0762 - accuracy: 0.8043 - val_loss: 0.1849 - val_accuracy: 0.8936\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.1340 - accuracy: 0.8261 - val_loss: 0.1456 - val_accuracy: 0.8936\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.1976 - accuracy: 0.8406 - val_loss: 0.1052 - val_accuracy: 0.8936\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -0.2687 - accuracy: 0.8551 - val_loss: 0.0640 - val_accuracy: 0.8936\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -0.3302 - accuracy: 0.8551 - val_loss: 0.0216 - val_accuracy: 0.8936\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.3967 - accuracy: 0.8551 - val_loss: -0.0223 - val_accuracy: 0.8936\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.4699 - accuracy: 0.8551 - val_loss: -0.0676 - val_accuracy: 0.8936\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.5398 - accuracy: 0.8551 - val_loss: -0.1158 - val_accuracy: 0.8936\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.6279 - accuracy: 0.8551 - val_loss: -0.1650 - val_accuracy: 0.8936\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -0.6937 - accuracy: 0.8551 - val_loss: -0.2194 - val_accuracy: 0.8936\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -0.7915 - accuracy: 0.8551 - val_loss: -0.2720 - val_accuracy: 0.8936\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -0.8823 - accuracy: 0.8551 - val_loss: -0.3286 - val_accuracy: 0.8936\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -0.9788 - accuracy: 0.8551 - val_loss: -0.3887 - val_accuracy: 0.8936\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -1.0675 - accuracy: 0.8551 - val_loss: -0.4485 - val_accuracy: 0.8936\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1.1727 - accuracy: 0.8551 - val_loss: -0.5097 - val_accuracy: 0.8936\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -1.2896 - accuracy: 0.8551 - val_loss: -0.5711 - val_accuracy: 0.8936\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -1.3986 - accuracy: 0.8551 - val_loss: -0.6393 - val_accuracy: 0.8936\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1.5241 - accuracy: 0.8551 - val_loss: -0.7096 - val_accuracy: 0.8936\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -1.6616 - accuracy: 0.8551 - val_loss: -0.7867 - val_accuracy: 0.8936\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: -1.7851 - accuracy: 0.8551 - val_loss: -0.8650 - val_accuracy: 0.8936\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1.9374 - accuracy: 0.8551 - val_loss: -0.9391 - val_accuracy: 0.8936\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -2.0810 - accuracy: 0.8551 - val_loss: -1.0181 - val_accuracy: 0.8936\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -2.2375 - accuracy: 0.8551 - val_loss: -1.1035 - val_accuracy: 0.8936\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: -2.4034 - accuracy: 0.8551 - val_loss: -1.1903 - val_accuracy: 0.8936\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -2.5635 - accuracy: 0.8551 - val_loss: -1.2839 - val_accuracy: 0.8936\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -2.7543 - accuracy: 0.8551 - val_loss: -1.3855 - val_accuracy: 0.8936\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: -2.9440 - accuracy: 0.8551 - val_loss: -1.5036 - val_accuracy: 0.8936\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3.1641 - accuracy: 0.8551 - val_loss: -1.6200 - val_accuracy: 0.8936\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -3.3783 - accuracy: 0.8551 - val_loss: -1.7444 - val_accuracy: 0.8936\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -3.6245 - accuracy: 0.8551 - val_loss: -1.8708 - val_accuracy: 0.8936\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -3.8790 - accuracy: 0.8551 - val_loss: -2.0007 - val_accuracy: 0.8936\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -4.1277 - accuracy: 0.8551 - val_loss: -2.1460 - val_accuracy: 0.8936\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -4.3990 - accuracy: 0.8551 - val_loss: -2.3004 - val_accuracy: 0.8936\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -4.6855 - accuracy: 0.8551 - val_loss: -2.4631 - val_accuracy: 0.8936\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -5.0228 - accuracy: 0.8551 - val_loss: -2.6264 - val_accuracy: 0.8936\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -5.3371 - accuracy: 0.8551 - val_loss: -2.8014 - val_accuracy: 0.8936\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -5.7153 - accuracy: 0.8551 - val_loss: -2.9829 - val_accuracy: 0.8936\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -6.0245 - accuracy: 0.8551 - val_loss: -3.2070 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6.5139 - accuracy: 0.8551 - val_loss: -3.4202 - val_accuracy: 0.8936\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -6.9681 - accuracy: 0.8551 - val_loss: -3.6726 - val_accuracy: 0.8936\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -7.4398 - accuracy: 0.8551 - val_loss: -3.9592 - val_accuracy: 0.8936\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -7.9449 - accuracy: 0.8551 - val_loss: -4.2460 - val_accuracy: 0.8936\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -8.5083 - accuracy: 0.8551 - val_loss: -4.5210 - val_accuracy: 0.8936\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -9.0167 - accuracy: 0.8551 - val_loss: -4.8251 - val_accuracy: 0.8936\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -9.6208 - accuracy: 0.8551 - val_loss: -5.1148 - val_accuracy: 0.8936\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -10.1656 - accuracy: 0.8551 - val_loss: -5.4427 - val_accuracy: 0.8936\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -10.7538 - accuracy: 0.8551 - val_loss: -5.7693 - val_accuracy: 0.8936\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -11.3455 - accuracy: 0.8551 - val_loss: -6.0965 - val_accuracy: 0.8936\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -12.0091 - accuracy: 0.8551 - val_loss: -6.4219 - val_accuracy: 0.8936\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -12.6064 - accuracy: 0.8551 - val_loss: -6.7884 - val_accuracy: 0.8936\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -13.3647 - accuracy: 0.8551 - val_loss: -7.1508 - val_accuracy: 0.8936\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -14.1049 - accuracy: 0.8551 - val_loss: -7.5506 - val_accuracy: 0.8936\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -14.8289 - accuracy: 0.8551 - val_loss: -7.9919 - val_accuracy: 0.8936\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -15.6815 - accuracy: 0.8551 - val_loss: -8.4659 - val_accuracy: 0.8936\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -16.6596 - accuracy: 0.8551 - val_loss: -8.9391 - val_accuracy: 0.8936\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -17.5780 - accuracy: 0.8551 - val_loss: -9.4558 - val_accuracy: 0.8936\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -18.5060 - accuracy: 0.8551 - val_loss: -10.0034 - val_accuracy: 0.8936\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -19.5542 - accuracy: 0.8551 - val_loss: -10.5602 - val_accuracy: 0.8936\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -20.5846 - accuracy: 0.8551 - val_loss: -11.1699 - val_accuracy: 0.8936\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -21.7923 - accuracy: 0.8551 - val_loss: -11.7918 - val_accuracy: 0.8936\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -22.8786 - accuracy: 0.8551 - val_loss: -12.4302 - val_accuracy: 0.8936\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -24.1792 - accuracy: 0.8551 - val_loss: -13.0962 - val_accuracy: 0.8936\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -25.3901 - accuracy: 0.8551 - val_loss: -13.7726 - val_accuracy: 0.8936\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -26.5167 - accuracy: 0.8551 - val_loss: -14.4800 - val_accuracy: 0.8936\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -27.9369 - accuracy: 0.8551 - val_loss: -15.1824 - val_accuracy: 0.8936\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -29.1534 - accuracy: 0.8551 - val_loss: -15.9305 - val_accuracy: 0.8936\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -30.6220 - accuracy: 0.8551 - val_loss: -16.6705 - val_accuracy: 0.8936\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -32.0234 - accuracy: 0.8551 - val_loss: -17.4453 - val_accuracy: 0.8936\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -33.4030 - accuracy: 0.8551 - val_loss: -18.3037 - val_accuracy: 0.8936\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -35.2698 - accuracy: 0.8551 - val_loss: -19.2009 - val_accuracy: 0.8936\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -36.8086 - accuracy: 0.8551 - val_loss: -20.2264 - val_accuracy: 0.8936\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -38.8968 - accuracy: 0.8551 - val_loss: -21.1864 - val_accuracy: 0.8936\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -40.5204 - accuracy: 0.8551 - val_loss: -22.2724 - val_accuracy: 0.8936\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -42.5479 - accuracy: 0.8551 - val_loss: -23.3270 - val_accuracy: 0.8936\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -44.5274 - accuracy: 0.8551 - val_loss: -24.4181 - val_accuracy: 0.8936\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -46.5369 - accuracy: 0.8551 - val_loss: -25.5154 - val_accuracy: 0.8936\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -48.6550 - accuracy: 0.8551 - val_loss: -26.6767 - val_accuracy: 0.8936\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -50.7090 - accuracy: 0.8551 - val_loss: -27.9135 - val_accuracy: 0.8936\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -53.2206 - accuracy: 0.8551 - val_loss: -29.1116 - val_accuracy: 0.8936\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -55.2572 - accuracy: 0.8551 - val_loss: -30.4698 - val_accuracy: 0.8936\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -57.9370 - accuracy: 0.8551 - val_loss: -31.8193 - val_accuracy: 0.8936\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -60.1123 - accuracy: 0.8551 - val_loss: -33.2753 - val_accuracy: 0.8936\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -63.2014 - accuracy: 0.8551 - val_loss: -34.6367 - val_accuracy: 0.8936\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -65.7038 - accuracy: 0.8551 - val_loss: -36.0887 - val_accuracy: 0.8936\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -68.4903 - accuracy: 0.8551 - val_loss: -37.6261 - val_accuracy: 0.8936\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -71.6351 - accuracy: 0.8551 - val_loss: -39.2443 - val_accuracy: 0.8936\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -74.6136 - accuracy: 0.8551 - val_loss: -41.0459 - val_accuracy: 0.8936\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -77.6797 - accuracy: 0.8551 - val_loss: -42.9462 - val_accuracy: 0.8936\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -80.9619 - accuracy: 0.8551 - val_loss: -44.7491 - val_accuracy: 0.8936\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -84.3963 - accuracy: 0.8551 - val_loss: -46.4573 - val_accuracy: 0.8936\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -87.4054 - accuracy: 0.8551 - val_loss: -48.2459 - val_accuracy: 0.8936\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -90.4479 - accuracy: 0.8551 - val_loss: -50.0715 - val_accuracy: 0.8936\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -93.9489 - accuracy: 0.8551 - val_loss: -51.9072 - val_accuracy: 0.8936\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -97.7084 - accuracy: 0.8551 - val_loss: -53.9048 - val_accuracy: 0.8936\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: -101.3397 - accuracy: 0.8551 - val_loss: -56.0763 - val_accuracy: 0.8936\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -105.1807 - accuracy: 0.8551 - val_loss: -58.2861 - val_accuracy: 0.8936\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -108.9557 - accuracy: 0.8551 - val_loss: -60.6688 - val_accuracy: 0.8936\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -113.3577 - accuracy: 0.8551 - val_loss: -63.0707 - val_accuracy: 0.8936\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -117.4380 - accuracy: 0.8551 - val_loss: -65.6380 - val_accuracy: 0.8936\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -122.4823 - accuracy: 0.8551 - val_loss: -68.1007 - val_accuracy: 0.8936\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -127.0657 - accuracy: 0.8551 - val_loss: -70.7366 - val_accuracy: 0.8936\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -131.5181 - accuracy: 0.8551 - val_loss: -73.5001 - val_accuracy: 0.8936\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -136.8313 - accuracy: 0.8551 - val_loss: -76.0877 - val_accuracy: 0.8936\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -141.6478 - accuracy: 0.8551 - val_loss: -78.8016 - val_accuracy: 0.8936\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -146.8455 - accuracy: 0.8551 - val_loss: -81.6216 - val_accuracy: 0.8936\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -151.7515 - accuracy: 0.8551 - val_loss: -84.7007 - val_accuracy: 0.8936\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -156.9711 - accuracy: 0.8551 - val_loss: -88.0497 - val_accuracy: 0.8936\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -163.1265 - accuracy: 0.8551 - val_loss: -91.4306 - val_accuracy: 0.8936\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -169.4027 - accuracy: 0.8551 - val_loss: -94.8702 - val_accuracy: 0.8936\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -175.1429 - accuracy: 0.8551 - val_loss: -98.7549 - val_accuracy: 0.8936\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -182.1679 - accuracy: 0.8551 - val_loss: -102.6197 - val_accuracy: 0.8936\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -188.8978 - accuracy: 0.8551 - val_loss: -106.5639 - val_accuracy: 0.8936\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -196.0222 - accuracy: 0.8551 - val_loss: -110.5563 - val_accuracy: 0.8936\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -203.0957 - accuracy: 0.8551 - val_loss: -114.5262 - val_accuracy: 0.8936\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -210.2827 - accuracy: 0.8551 - val_loss: -118.6121 - val_accuracy: 0.8936\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -217.8181 - accuracy: 0.8551 - val_loss: -122.7887 - val_accuracy: 0.8936\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -225.2188 - accuracy: 0.8551 - val_loss: -127.4573 - val_accuracy: 0.8936\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -233.7211 - accuracy: 0.8551 - val_loss: -132.2633 - val_accuracy: 0.8936\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -242.7657 - accuracy: 0.8551 - val_loss: -137.4169 - val_accuracy: 0.8936\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -251.1176 - accuracy: 0.8551 - val_loss: -143.2239 - val_accuracy: 0.8936\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -261.4763 - accuracy: 0.8551 - val_loss: -149.1687 - val_accuracy: 0.8936\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -273.0718 - accuracy: 0.8551 - val_loss: -154.8715 - val_accuracy: 0.8936\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -284.0647 - accuracy: 0.8551 - val_loss: -161.1459 - val_accuracy: 0.8936\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -293.1104 - accuracy: 0.8551 - val_loss: -167.9840 - val_accuracy: 0.8936\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -305.4720 - accuracy: 0.8551 - val_loss: -174.2121 - val_accuracy: 0.8936\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -316.4154 - accuracy: 0.8551 - val_loss: -180.2768 - val_accuracy: 0.8936\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -328.4472 - accuracy: 0.8551 - val_loss: -186.2318 - val_accuracy: 0.8936\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -339.2465 - accuracy: 0.8551 - val_loss: -192.9698 - val_accuracy: 0.8936\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -351.1643 - accuracy: 0.8551 - val_loss: -200.1878 - val_accuracy: 0.8936\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -363.8955 - accuracy: 0.8551 - val_loss: -207.3967 - val_accuracy: 0.8936\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -375.7585 - accuracy: 0.8551 - val_loss: -214.7365 - val_accuracy: 0.8936\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -389.7116 - accuracy: 0.8551 - val_loss: -221.8489 - val_accuracy: 0.8936\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -402.3708 - accuracy: 0.8551 - val_loss: -229.1605 - val_accuracy: 0.8936\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -416.0369 - accuracy: 0.8551 - val_loss: -236.6115 - val_accuracy: 0.8936\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -429.0593 - accuracy: 0.8551 - val_loss: -244.5175 - val_accuracy: 0.8936\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -443.0959 - accuracy: 0.8551 - val_loss: -252.8037 - val_accuracy: 0.8936\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -457.8833 - accuracy: 0.8551 - val_loss: -261.0285 - val_accuracy: 0.8936\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -472.7982 - accuracy: 0.8551 - val_loss: -269.7927 - val_accuracy: 0.8936\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -488.4655 - accuracy: 0.8551 - val_loss: -278.5131 - val_accuracy: 0.8936\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -503.2575 - accuracy: 0.8551 - val_loss: -287.4762 - val_accuracy: 0.8936\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -520.4515 - accuracy: 0.8551 - val_loss: -296.6640 - val_accuracy: 0.8936\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -536.5138 - accuracy: 0.8551 - val_loss: -306.2892 - val_accuracy: 0.8936\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -552.6288 - accuracy: 0.8551 - val_loss: -315.7379 - val_accuracy: 0.8936\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -569.0508 - accuracy: 0.8551 - val_loss: -325.2324 - val_accuracy: 0.8936\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -586.4615 - accuracy: 0.8551 - val_loss: -335.3351 - val_accuracy: 0.8936\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -605.3422 - accuracy: 0.8551 - val_loss: -345.7508 - val_accuracy: 0.8936\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -624.7211 - accuracy: 0.8551 - val_loss: -356.9771 - val_accuracy: 0.8936\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -642.7765 - accuracy: 0.8551 - val_loss: -368.8738 - val_accuracy: 0.8936\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -664.8811 - accuracy: 0.8551 - val_loss: -380.7488 - val_accuracy: 0.8936\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: -686.6966 - accuracy: 0.8551 - val_loss: -392.7829 - val_accuracy: 0.8936\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -706.8575 - accuracy: 0.8551 - val_loss: -404.6039 - val_accuracy: 0.8936\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -728.2422 - accuracy: 0.8551 - val_loss: -416.2426 - val_accuracy: 0.8936\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -749.0485 - accuracy: 0.8551 - val_loss: -428.4209 - val_accuracy: 0.8936\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -770.4348 - accuracy: 0.8551 - val_loss: -441.0002 - val_accuracy: 0.8936\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -792.7574 - accuracy: 0.8551 - val_loss: -453.9080 - val_accuracy: 0.8936\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -815.3629 - accuracy: 0.8551 - val_loss: -466.6734 - val_accuracy: 0.8936\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -837.8267 - accuracy: 0.8551 - val_loss: -481.0009 - val_accuracy: 0.8936\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -860.1319 - accuracy: 0.8551 - val_loss: -494.9512 - val_accuracy: 0.8936\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -887.0632 - accuracy: 0.8551 - val_loss: -507.7453 - val_accuracy: 0.8936\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -907.8849 - accuracy: 0.8551 - val_loss: -521.6205 - val_accuracy: 0.8936\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -934.4374 - accuracy: 0.8551 - val_loss: -534.9451 - val_accuracy: 0.8936\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -958.3317 - accuracy: 0.8551 - val_loss: -548.9315 - val_accuracy: 0.8936\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -982.4489 - accuracy: 0.8551 - val_loss: -564.0917 - val_accuracy: 0.8936\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1010.6993 - accuracy: 0.8551 - val_loss: -579.5979 - val_accuracy: 0.8936\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1036.7881 - accuracy: 0.8551 - val_loss: -596.0196 - val_accuracy: 0.8936\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -1063.3408 - accuracy: 0.8551 - val_loss: -612.7212 - val_accuracy: 0.8936\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1094.2654 - accuracy: 0.8551 - val_loss: -628.6143 - val_accuracy: 0.8936\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -1121.0914 - accuracy: 0.8551 - val_loss: -644.3062 - val_accuracy: 0.8936\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1150.6063 - accuracy: 0.8551 - val_loss: -659.9162 - val_accuracy: 0.8936\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1176.4778 - accuracy: 0.8551 - val_loss: -676.8363 - val_accuracy: 0.8936\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1207.4702 - accuracy: 0.8551 - val_loss: -692.9387 - val_accuracy: 0.8936\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1235.2080 - accuracy: 0.8551 - val_loss: -709.5333 - val_accuracy: 0.8936\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1266.7214 - accuracy: 0.8551 - val_loss: -726.1226 - val_accuracy: 0.8936\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1294.3872 - accuracy: 0.8551 - val_loss: -743.6103 - val_accuracy: 0.8936\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -1322.5612 - accuracy: 0.8551 - val_loss: -762.2506 - val_accuracy: 0.8936\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -1357.2639 - accuracy: 0.8551 - val_loss: -779.5632 - val_accuracy: 0.8936\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1387.1051 - accuracy: 0.8551 - val_loss: -797.8536 - val_accuracy: 0.8936\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -1418.9814 - accuracy: 0.8551 - val_loss: -816.4850 - val_accuracy: 0.8936\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1452.8148 - accuracy: 0.8551 - val_loss: -835.0234 - val_accuracy: 0.8936\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1484.0331 - accuracy: 0.8551 - val_loss: -854.2025 - val_accuracy: 0.8936\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1518.3682 - accuracy: 0.8551 - val_loss: -872.8571 - val_accuracy: 0.8936\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1550.4270 - accuracy: 0.8551 - val_loss: -892.3973 - val_accuracy: 0.8936\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: -1589.7498 - accuracy: 0.8551 - val_loss: -912.6469 - val_accuracy: 0.8936\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -1623.7723 - accuracy: 0.8551 - val_loss: -936.1071 - val_accuracy: 0.8936\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -1664.4070 - accuracy: 0.8551 - val_loss: -958.2286 - val_accuracy: 0.8936\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -1707.3287 - accuracy: 0.8551 - val_loss: -979.9867 - val_accuracy: 0.8936\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1742.4156 - accuracy: 0.8551 - val_loss: -1003.2027 - val_accuracy: 0.8936\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1779.8058 - accuracy: 0.8551 - val_loss: -1027.3842 - val_accuracy: 0.8936\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1821.4104 - accuracy: 0.8551 - val_loss: -1051.0874 - val_accuracy: 0.8936\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -1866.8057 - accuracy: 0.8551 - val_loss: -1072.4875 - val_accuracy: 0.8936\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1901.7942 - accuracy: 0.8551 - val_loss: -1095.9288 - val_accuracy: 0.8936\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -1943.9343 - accuracy: 0.8551 - val_loss: -1120.5322 - val_accuracy: 0.8936\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -1988.3818 - accuracy: 0.8551 - val_loss: -1146.3121 - val_accuracy: 0.8936\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2034.6947 - accuracy: 0.8551 - val_loss: -1172.1696 - val_accuracy: 0.8936\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2082.1030 - accuracy: 0.8551 - val_loss: -1198.4668 - val_accuracy: 0.8936\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -2126.0352 - accuracy: 0.8551 - val_loss: -1226.2150 - val_accuracy: 0.8936\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2174.8035 - accuracy: 0.8551 - val_loss: -1254.2455 - val_accuracy: 0.8936\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -2223.2646 - accuracy: 0.8551 - val_loss: -1280.5013 - val_accuracy: 0.8936\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -2265.4690 - accuracy: 0.8551 - val_loss: -1307.9590 - val_accuracy: 0.8936\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2310.5796 - accuracy: 0.8551 - val_loss: -1334.0546 - val_accuracy: 0.8936\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2357.3528 - accuracy: 0.8551 - val_loss: -1359.2941 - val_accuracy: 0.8936\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -2407.6492 - accuracy: 0.8551 - val_loss: -1385.2899 - val_accuracy: 0.8936\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2449.3528 - accuracy: 0.8551 - val_loss: -1413.9977 - val_accuracy: 0.8936\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -2501.5989 - accuracy: 0.8551 - val_loss: -1440.4889 - val_accuracy: 0.8936\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: -2545.9446 - accuracy: 0.8551 - val_loss: -1467.0426 - val_accuracy: 0.8936\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -2586.6279 - accuracy: 0.8551 - val_loss: -1494.7292 - val_accuracy: 0.8936\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -2640.7900 - accuracy: 0.8551 - val_loss: -1520.7085 - val_accuracy: 0.8936\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -2687.4309 - accuracy: 0.8551 - val_loss: -1547.9283 - val_accuracy: 0.8936\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2734.4089 - accuracy: 0.8551 - val_loss: -1575.7340 - val_accuracy: 0.8936\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -2788.1172 - accuracy: 0.8551 - val_loss: -1602.3805 - val_accuracy: 0.8936\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -2828.2292 - accuracy: 0.8551 - val_loss: -1633.6113 - val_accuracy: 0.8936\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -2883.8613 - accuracy: 0.8551 - val_loss: -1662.7334 - val_accuracy: 0.8936\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -2933.4702 - accuracy: 0.8551 - val_loss: -1691.3488 - val_accuracy: 0.8936\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -2984.5869 - accuracy: 0.8551 - val_loss: -1719.8291 - val_accuracy: 0.8936\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -3031.8804 - accuracy: 0.8551 - val_loss: -1749.9543 - val_accuracy: 0.8936\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -3093.9111 - accuracy: 0.8551 - val_loss: -1778.8324 - val_accuracy: 0.8936\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3139.9021 - accuracy: 0.8551 - val_loss: -1812.8451 - val_accuracy: 0.8936\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3199.3667 - accuracy: 0.8551 - val_loss: -1849.3639 - val_accuracy: 0.8936\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3266.0281 - accuracy: 0.8551 - val_loss: -1882.8571 - val_accuracy: 0.8936\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -3318.3499 - accuracy: 0.8551 - val_loss: -1917.1559 - val_accuracy: 0.8936\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -3381.4285 - accuracy: 0.8551 - val_loss: -1951.9778 - val_accuracy: 0.8936\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3442.1047 - accuracy: 0.8551 - val_loss: -1988.3264 - val_accuracy: 0.8936\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -3499.8203 - accuracy: 0.8551 - val_loss: -2024.4628 - val_accuracy: 0.8936\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3570.0171 - accuracy: 0.8551 - val_loss: -2057.9653 - val_accuracy: 0.8936\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3629.2417 - accuracy: 0.8551 - val_loss: -2093.6055 - val_accuracy: 0.8936\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -3690.4001 - accuracy: 0.8551 - val_loss: -2131.5837 - val_accuracy: 0.8936\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -3757.3174 - accuracy: 0.8551 - val_loss: -2170.0535 - val_accuracy: 0.8936\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -3820.4421 - accuracy: 0.8551 - val_loss: -2208.5112 - val_accuracy: 0.8936\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -3888.1680 - accuracy: 0.8551 - val_loss: -2244.8596 - val_accuracy: 0.8936\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -3953.0239 - accuracy: 0.8551 - val_loss: -2281.0159 - val_accuracy: 0.8936\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -4012.3442 - accuracy: 0.8551 - val_loss: -2317.3103 - val_accuracy: 0.8936\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -4074.8677 - accuracy: 0.8551 - val_loss: -2353.3279 - val_accuracy: 0.8936\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -4140.6890 - accuracy: 0.8551 - val_loss: -2388.1831 - val_accuracy: 0.8936\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -4202.2280 - accuracy: 0.8551 - val_loss: -2424.2002 - val_accuracy: 0.8936\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: -4266.6831 - accuracy: 0.8551 - val_loss: -2460.8108 - val_accuracy: 0.8936\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -4331.9302 - accuracy: 0.8551 - val_loss: -2500.0532 - val_accuracy: 0.8936\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -4401.3120 - accuracy: 0.8551 - val_loss: -2541.1680 - val_accuracy: 0.8936\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -4469.4546 - accuracy: 0.8551 - val_loss: -2583.2046 - val_accuracy: 0.8936\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: -4543.1240 - accuracy: 0.8551 - val_loss: -2626.7927 - val_accuracy: 0.8936\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -4622.0884 - accuracy: 0.8551 - val_loss: -2667.6216 - val_accuracy: 0.8936\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -4699.3184 - accuracy: 0.8551 - val_loss: -2707.6523 - val_accuracy: 0.8936\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: -4772.0366 - accuracy: 0.8551 - val_loss: -2751.4065 - val_accuracy: 0.8936\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -4840.8643 - accuracy: 0.8551 - val_loss: -2799.9290 - val_accuracy: 0.8936\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -4918.6958 - accuracy: 0.8551 - val_loss: -2846.5112 - val_accuracy: 0.8936\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -5007.8042 - accuracy: 0.8551 - val_loss: -2890.8726 - val_accuracy: 0.8936\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -5081.1826 - accuracy: 0.8551 - val_loss: -2937.2373 - val_accuracy: 0.8936\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -5162.1611 - accuracy: 0.8551 - val_loss: -2981.6018 - val_accuracy: 0.8936\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -5242.8770 - accuracy: 0.8551 - val_loss: -3024.2368 - val_accuracy: 0.8936\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -5316.0010 - accuracy: 0.8551 - val_loss: -3069.4248 - val_accuracy: 0.8936\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -5395.3696 - accuracy: 0.8551 - val_loss: -3116.5259 - val_accuracy: 0.8936\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -5479.8696 - accuracy: 0.8551 - val_loss: -3164.5154 - val_accuracy: 0.8936\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -5559.0518 - accuracy: 0.8551 - val_loss: -3212.2742 - val_accuracy: 0.8936\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: -5648.1460 - accuracy: 0.8551 - val_loss: -3259.9688 - val_accuracy: 0.8936\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -5719.5796 - accuracy: 0.8551 - val_loss: -3312.3613 - val_accuracy: 0.8936\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -5812.6357 - accuracy: 0.8551 - val_loss: -3360.8667 - val_accuracy: 0.8936\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -5904.8950 - accuracy: 0.8551 - val_loss: -3407.2732 - val_accuracy: 0.8936\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -5981.1035 - accuracy: 0.8551 - val_loss: -3458.1409 - val_accuracy: 0.8936\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -6074.9727 - accuracy: 0.8551 - val_loss: -3507.3904 - val_accuracy: 0.8936\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6163.8223 - accuracy: 0.8551 - val_loss: -3561.3528 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6254.0571 - accuracy: 0.8551 - val_loss: -3618.3186 - val_accuracy: 0.8936\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -6363.2148 - accuracy: 0.8551 - val_loss: -3674.6948 - val_accuracy: 0.8936\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6441.1973 - accuracy: 0.8551 - val_loss: -3738.2212 - val_accuracy: 0.8936\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -6565.7593 - accuracy: 0.8551 - val_loss: -3792.3762 - val_accuracy: 0.8936\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6664.2969 - accuracy: 0.8551 - val_loss: -3847.4421 - val_accuracy: 0.8936\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6764.0757 - accuracy: 0.8551 - val_loss: -3911.7161 - val_accuracy: 0.8936\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6864.1655 - accuracy: 0.8551 - val_loss: -3978.4338 - val_accuracy: 0.8936\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -6987.4502 - accuracy: 0.8551 - val_loss: -4036.0205 - val_accuracy: 0.8936\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -7086.8848 - accuracy: 0.8551 - val_loss: -4094.7234 - val_accuracy: 0.8936\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -7187.4111 - accuracy: 0.8551 - val_loss: -4159.1104 - val_accuracy: 0.8936\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -7293.4580 - accuracy: 0.8551 - val_loss: -4219.0146 - val_accuracy: 0.8936\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -7391.9287 - accuracy: 0.8551 - val_loss: -4276.0234 - val_accuracy: 0.8936\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -7495.7554 - accuracy: 0.8551 - val_loss: -4330.2241 - val_accuracy: 0.8936\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -7597.6670 - accuracy: 0.8551 - val_loss: -4388.9985 - val_accuracy: 0.8936\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -7695.4395 - accuracy: 0.8551 - val_loss: -4454.7964 - val_accuracy: 0.8936\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -7800.6577 - accuracy: 0.8551 - val_loss: -4518.1152 - val_accuracy: 0.8936\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -7912.5718 - accuracy: 0.8551 - val_loss: -4581.8857 - val_accuracy: 0.8936\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -8019.1558 - accuracy: 0.8551 - val_loss: -4647.0361 - val_accuracy: 0.8936\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -8135.3560 - accuracy: 0.8551 - val_loss: -4708.7490 - val_accuracy: 0.8936\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: -8242.9844 - accuracy: 0.8551 - val_loss: -4767.9922 - val_accuracy: 0.8936\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -8332.5439 - accuracy: 0.8551 - val_loss: -4828.1484 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ccaf024970>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 32, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 3]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0]\n",
      " [ 4  0  0]\n",
      " [ 1  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8936170212765957"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
